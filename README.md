# Beyond Random Augmentations: Pretraining with Hard Views

Other branches are available here (required for double-blind submission):
- [SimSiam Branch (main)](https://anonymous.4open.science/r/pretraining-hard-views/)
- [DINO branch](https://anonymous.4open.science/r/pretraining-hard-views-dino/)
- [SimCLR Branch](https://anonymous.4open.science/r/pretraining-hard-views-simclr/)

## Introduction

## Download Model Files
(include pretraining, linear evaluation and finetuning checkpoints)
- [DINO models](https://shorturl.at/ceA38) (45G)
- [iBOT models](https://shorturl.at/pGS28) (11G)
- [SimSiam models](https://shorturl.at/rxCKO) (20G)
- [SimCLR models](https://shorturl.at/dBDV7) (66G)
